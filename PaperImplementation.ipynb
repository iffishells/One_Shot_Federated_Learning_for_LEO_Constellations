{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Cell 0: Setup\n",
   "id": "f54426299c794a59"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-23T01:45:27.356329Z",
     "start_time": "2025-12-23T01:45:26.615790Z"
    }
   },
   "source": [
    "\n",
    "import random, copy, time\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "torch.manual_seed(42); np.random.seed(42); random.seed(42)\n",
    "\n",
    "# Speed knob: set FAST=True for quick runs (fewer samples/epochs)\n",
    "FAST = False\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Cell 1: MNIST loaders (resize to 224, 3-channels for ResNet)\n",
    "# Paper used MNIST and CIFAR‑10; we adapt MNIST to ResNet input shape.\n",
    "# Reference dataset: Deng, 2012. [1](https://o365khu-my.sharepoint.com/personal/2025315503_office_khu_ac_kr/Documents/Microsoft%20Copilot%20Chat%20Files/One-Shot%20Federated%20Learning%20for%20LEO%20Constellations.pdf)\n"
   ],
   "id": "64141ad1b2f0119c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T01:45:28.620536Z",
     "start_time": "2025-12-23T01:45:28.570822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "tf_train = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n",
    "])\n",
    "tf_test = tf_train  # same normalization for test/distillation\n",
    "\n",
    "mnist_train = datasets.MNIST(root=\"./data\", train=True, download=True, transform=tf_train)\n",
    "mnist_test  = datasets.MNIST(root=\"./data\", train=False, download=True, transform=tf_test)\n",
    "\n",
    "print(\"Train size:\", len(mnist_train), \"Test size:\", len(mnist_test))\n"
   ],
   "id": "5d753f729d6f2cef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 60000 Test size: 10000\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Cell 2: Non‑IID orbit splits (5 orbits; 2 with 4 classes, 3 with 6 classes)\n",
    "# Mirrors the paper's non‑IID setting (4 vs 6 classes per orbit). [1](https://o365khu-my.sharepoint.com/personal/2025315503_office_khu_ac_kr/Documents/Microsoft%20Copilot%20Chat%20Files/One-Shot%20Federated%20Learning%20for%20LEO%20Constellations.pdf\n"
   ],
   "id": "1acaa123a8d1f79e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T01:48:38.839025Z",
     "start_time": "2025-12-23T01:45:30.796181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Cell 2: Non‑IID orbit splits (5 orbits; 2 with 4 classes, 3 with 6 classes)\n",
    "# Mirrors the paper's non‑IID setting (4 vs 6 classes per orbit). [1](https://o365khu-my.sharepoint.com/personal/2025315503_office_khu_ac_kr/Documents/Microsoft%20Copilot%20Chat%20Files/One-Shot%20Federated%20Learning%20for%20LEO%20Constellations.pdf)\n",
    "\n",
    "# Fixed deterministic split\n",
    "orbit_labels = [\n",
    "    [0,1,2,3],                # Orbit 1 (4 classes)\n",
    "    [4,5,6,7],                # Orbit 2 (4 classes)\n",
    "    [0,1,2,3,4,5],            # Orbit 3 (6 classes)\n",
    "    [6,7,8,9,0,1],            # Orbit 4 (6 classes)\n",
    "    [2,3,4,5,8,9]             # Orbit 5 (6 classes)\n",
    "]\n",
    "\n",
    "def idxs_for_labels(dataset, labels):\n",
    "    return [i for i,(x,y) in enumerate(dataset) if y in labels]\n",
    "\n",
    "train_orbit_subsets, val_orbit_subsets = [], []\n",
    "for lbls in orbit_labels:\n",
    "    idxs = idxs_for_labels(mnist_train, lbls)\n",
    "    random.shuffle(idxs)\n",
    "    split = int(0.85 * len(idxs))  # 85/15 train/val\n",
    "    tr_idx, va_idx = idxs[:split], idxs[split:]\n",
    "    if FAST:\n",
    "        tr_idx = tr_idx[:800]  # shrink per orbit for speed\n",
    "        va_idx = va_idx[:200]\n",
    "    train_orbit_subsets.append(Subset(mnist_train, tr_idx))\n",
    "    val_orbit_subsets.append(Subset(mnist_train, va_idx))\n",
    "\n",
    "for i,lbls in enumerate(orbit_labels, 1):\n",
    "    print(f\"Orbit {i}: labels {lbls}, train {len(train_orbit_subsets[i-1])}, val {len(val_orbit_subsets[i-1])}\")\n"
   ],
   "id": "788157b71d650489",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orbit 1: labels [0, 1, 2, 3], train 21040, val 3714\n",
      "Orbit 2: labels [4, 5, 6, 7], train 19929, val 3517\n",
      "Orbit 3: labels [0, 1, 2, 3, 4, 5], train 30614, val 5403\n",
      "Orbit 4: labels [6, 7, 8, 9, 0, 1], train 31150, val 5498\n",
      "Orbit 5: labels [2, 3, 4, 5, 8, 9], train 29879, val 5273\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Cell 3: Build ResNet-50 teachers (first conv already 3-channels; we train from scratch)\n",
    "# Paper trained ResNet‑50 locally on clients and used ResNet‑18 as the student at server. [1](https://o365khu-my.sharepoint.com/personal/2025315503_office_khu_ac_kr/Documents/Microsoft%20Copilot%20Chat%20Files/One-Shot%20Federated%20Learning%20for%20LEO%20Constellations.pdf)"
   ],
   "id": "5544e49f958b2d63"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T01:43:21.823528Z",
     "start_time": "2025-12-23T01:43:21.821404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "def make_resnet50(n_classes=10):\n",
    "    m = models.resnet50(weights=None)  # no pretrain (offline-friendly)\n",
    "    m.fc = nn.Linear(m.fc.in_features, n_classes)\n",
    "    return m\n",
    "\n",
    "def make_resnet18(n_classes=10):\n",
    "    m = models.resnet18(weights=None)\n",
    "    m.fc = nn.Linear(m.fc.in_features, n_classes)\n",
    "    return m\n",
    "\n"
   ],
   "id": "e3538796dd60da93",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Cell 4: Train one teacher (ResNet‑50) on an orbit split\n",
   "id": "e5c3a8e4e6e506c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T08:34:47.295948Z",
     "start_time": "2025-12-22T08:33:10.077072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def train_teacher(model, train_subset, val_subset, epochs=3, lr=1e-3, bs=64):\n",
    "    model = model.to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    train_loader = DataLoader(train_subset, batch_size=bs, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    val_loader   = DataLoader(val_subset, batch_size=bs, num_workers=2, pin_memory=True)\n",
    "    for ep in range(epochs):\n",
    "        model.train(); total=0; correct=0; loss_sum=0.0\n",
    "        for x,y in train_loader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            loss   = F.cross_entropy(logits, y)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "            loss_sum += loss.item() * x.size(0)\n",
    "            correct  += (logits.argmax(1)==y).sum().item()\n",
    "            total    += x.size(0)\n",
    "        # val\n",
    "        model.eval(); vtot=0; vcor=0\n",
    "        with torch.no_grad():\n",
    "            for x,y in val_loader:\n",
    "                x,y = x.to(device), y.to(device)\n",
    "                out = model(x)\n",
    "                vcor += (out.argmax(1)==y).sum().item()\n",
    "                vtot += x.size(0)\n",
    "        print(f\"Teacher ep {ep+1}: train loss {loss_sum/total:.3f}, train acc {correct/total:.3f}, val acc {vcor/vtot:.3f}\")\n",
    "    return model.eval()\n",
    "\n",
    "# Train 5 teachers\n",
    "teachers = []\n",
    "for i,(tr,va) in enumerate(zip(train_orbit_subsets, val_orbit_subsets), 1):\n",
    "    print(f\"\\nTraining ResNet-50 Teacher for Orbit {i} (labels {orbit_labels[i-1]})\")\n",
    "    t = make_resnet50()\n",
    "    t = train_teacher(t, tr, va, epochs=(2 if FAST else 6), lr=1e-3, bs=(32 if FAST else 64))\n",
    "    teachers.append(t)\n"
   ],
   "id": "911d793726d4de0d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training ResNet-50 Teacher for Orbit 1 (labels [0, 1, 2, 3])\n",
      "Teacher ep 1: train loss 0.712, train acc 0.751, val acc 0.310\n",
      "Teacher ep 2: train loss 0.167, train acc 0.948, val acc 0.920\n",
      "\n",
      "Training ResNet-50 Teacher for Orbit 2 (labels [4, 5, 6, 7])\n",
      "Teacher ep 1: train loss 0.668, train acc 0.769, val acc 0.495\n",
      "Teacher ep 2: train loss 0.138, train acc 0.948, val acc 0.920\n",
      "\n",
      "Training ResNet-50 Teacher for Orbit 3 (labels [0, 1, 2, 3, 4, 5])\n",
      "Teacher ep 1: train loss 1.046, train acc 0.637, val acc 0.140\n",
      "Teacher ep 2: train loss 0.265, train acc 0.919, val acc 0.775\n",
      "\n",
      "Training ResNet-50 Teacher for Orbit 4 (labels [6, 7, 8, 9, 0, 1])\n",
      "Teacher ep 1: train loss 0.894, train acc 0.664, val acc 0.590\n",
      "Teacher ep 2: train loss 0.284, train acc 0.909, val acc 0.890\n",
      "\n",
      "Training ResNet-50 Teacher for Orbit 5 (labels [2, 3, 4, 5, 8, 9])\n",
      "Teacher ep 1: train loss 1.166, train acc 0.590, val acc 0.445\n",
      "Teacher ep 2: train loss 0.316, train acc 0.891, val acc 0.815\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "46780eaf5321f64e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Cell 5: Server distillation dataset (proxy)\n",
   "id": "74d3102c4ad43dc5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T08:40:21.450021Z",
     "start_time": "2025-12-22T08:34:52.904263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# In the paper, Phase 1 generates synthetic data; here we use MNIST test as the server's proxy for KD,\n",
    "# which is a standard practice to demonstrate Phase 2 mechanics (data-free generator omitted for brevity). [1](https://o365khu-my.sharepoint.com/personal/2025315503_office_khu_ac_kr/Documents/Microsoft%20Copilot%20Chat%20Files/One-Shot%20Federated%20Learning%20for%20LEO%20Constellations.pdf)\n",
    "\n",
    "kd_loader   = DataLoader(mnist_test, batch_size=(64 if FAST else 128), shuffle=True, num_workers=2, pin_memory=True)\n",
    "eval_loader = DataLoader(mnist_test, batch_size=(64 if FAST else 128), num_workers=2, pin_memory=True)\n",
    "\n",
    "# Quick evaluation utilities\n",
    "def eval_acc(model, loader):\n",
    "    model.eval(); tot=0; cor=0\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            cor += (out.argmax(1)==y).sum().item(); tot += x.size(0)\n",
    "    return cor/tot\n",
    "\n",
    "def eval_ensemble_acc(teachers, loader, weights=None):\n",
    "    for m in teachers: m.eval()\n",
    "    tot=0; cor=0\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            logits = [m(x) for m in teachers]\n",
    "            if weights is None:\n",
    "                ens = torch.stack(logits).mean(dim=0)\n",
    "            else:\n",
    "                w = torch.tensor(weights, device=device).view(-1,1,1)\n",
    "                ens = (torch.stack(logits)*w).sum(dim=0)\n",
    "            cor += (ens.argmax(1)==y).sum().item(); tot += x.size(0)\n",
    "    return cor/tot\n",
    "\n",
    "# Teacher and ensemble baseline accuracy (sanity check)\n",
    "teacher_accs = [eval_acc(t, eval_loader) for t in teachers]\n",
    "ens_acc = eval_ensemble_acc(teachers, eval_loader)\n",
    "print(\"\\nTeacher accuracies:\", teacher_accs)\n",
    "print(\"Unweighted ensemble accuracy:\", ens_acc)\n"
   ],
   "id": "83451205dc5212e4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Teacher accuracies: [0.3893, 0.3578, 0.4571, 0.5294, 0.5036]\n",
      "Unweighted ensemble accuracy: 0.5672\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Cell 6: Phase 2 KD — train ResNet‑18 student to match teacher ensemble (KL loss with temperature)\n",
   "id": "31880178cd00495d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T09:01:35.947189Z",
     "start_time": "2025-12-22T08:40:21.501696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Paper's KD objective: R_KL^S = KL(D_teacher, D_student); student updates by SGD/Adam. [1](https://o365khu-my.sharepoint.com/personal/2025315503_office_khu_ac_kr/Documents/Microsoft%20Copilot%20Chat%20Files/One-Shot%20Federated%20Learning%20for%20LEO%20Constellations.pdf)\n",
    "\n",
    "@dataclass\n",
    "class KDConfig:\n",
    "    T: float = 3.0           # temperature\n",
    "    lr: float = 5e-4\n",
    "    epochs: int = (6 if FAST else 12)\n",
    "    clip_grad: float = 1.0\n",
    "    conf_th: float = 0.70     # keep confident teacher consensus\n",
    "    use_weights: bool = True  # weight teachers by accuracy\n",
    "\n",
    "# Teacher weights from their eval accuracy\n",
    "weights = np.array(teacher_accs)\n",
    "weights = weights / (weights.sum() + 1e-8)\n",
    "\n",
    "student = make_resnet18().to(device)\n",
    "opt = torch.optim.SGD(student.parameters(), lr=KDConfig.lr, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "for ep in range(KDConfig.epochs):\n",
    "    student.train(); loss_sum=0; kept=0\n",
    "    for x,_ in kd_loader:\n",
    "        x = x.to(device)\n",
    "        with torch.no_grad():\n",
    "            logits_list = [m(x) for m in teachers]\n",
    "            if KDConfig.use_weights:\n",
    "                w = torch.tensor(weights, device=device).view(-1,1,1)\n",
    "                D_teacher = (torch.stack(logits_list) * w).sum(dim=0)\n",
    "            else:\n",
    "                D_teacher = torch.stack(logits_list).mean(dim=0)\n",
    "        D_student = student(x)\n",
    "\n",
    "        # Temperature-softened distributions\n",
    "        p = F.softmax(D_teacher / KDConfig.T, dim=1)\n",
    "        q_log = F.log_softmax(D_student / KDConfig.T, dim=1)\n",
    "\n",
    "        # Confidence filter: only learn from strong consensus\n",
    "        maxp, _ = p.max(dim=1)\n",
    "        mask = (maxp >= KDConfig.conf_th)\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        kept += mask.sum().item()\n",
    "        p_sel  = p[mask]\n",
    "        q_log_sel = q_log[mask]\n",
    "\n",
    "        loss = F.kl_div(q_log_sel, p_sel, reduction='batchmean') * (KDConfig.T**2)\n",
    "        opt.zero_grad(); loss.backward()\n",
    "        if KDConfig.clip_grad: nn.utils.clip_grad_norm_(student.parameters(), KDConfig.clip_grad)\n",
    "        opt.step()\n",
    "        loss_sum += loss.item()\n",
    "\n",
    "    # quick eval\n",
    "    student.eval(); tot=0; cor=0\n",
    "    with torch.no_grad():\n",
    "        for x,y in eval_loader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            out = student(x)\n",
    "            cor += (out.argmax(1)==y).sum().item(); tot += x.size(0)\n",
    "    print(f\"KD Epoch {ep+1}: train KL {loss_sum/max(1,kept):.4f}, eval acc {cor/tot:.3f}, kept {kept}\")\n"
   ],
   "id": "21cbf1a015b09b5a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KD Epoch 1: train KL 1.9537, eval acc 0.114, kept 531\n",
      "KD Epoch 2: train KL 0.5747, eval acc 0.114, kept 531\n",
      "KD Epoch 3: train KL 0.3968, eval acc 0.114, kept 531\n",
      "KD Epoch 4: train KL 0.3871, eval acc 0.114, kept 531\n",
      "KD Epoch 5: train KL 0.2814, eval acc 0.114, kept 531\n",
      "KD Epoch 6: train KL 0.2656, eval acc 0.126, kept 531\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Cell 7: Final evaluation + (optional) Phase 3 virtual retraining\n",
   "id": "d538ded67a05a4c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T09:02:20.974135Z",
     "start_time": "2025-12-22T09:01:36.092417Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "print(\"Final student accuracy:\", eval_acc(student, eval_loader))\n",
    "\n",
    "# OPTIONAL: Server-local virtual retraining (Phase 3 idea from the paper). [1](https://o365khu-my.sharepoint.com/personal/2025315503_office_khu_ac_kr/Documents/Microsoft%20Copilot%20Chat%20Files/One-Shot%20Federated%20Learning%20for%20LEO%20Constellations.pdf)\n",
    "# Clone several virtual students, train each on an \"orbit-style\" partition of MNIST test, then average.\n",
    "\n",
    "def subset_by_labels(dataset, labels, limit=None):\n",
    "    idxs = [i for i,(x,y) in enumerate(dataset) if y in labels]\n",
    "    if FAST and limit: idxs = idxs[:limit]\n",
    "    return Subset(dataset, idxs)\n",
    "\n",
    "parts = [\n",
    "    subset_by_labels(mnist_test, orbit_labels[2], limit=1000),  # mimic a 6-class partition\n",
    "    subset_by_labels(mnist_test, orbit_labels[3], limit=1000),\n",
    "    subset_by_labels(mnist_test, orbit_labels[4], limit=1000),\n",
    "]\n",
    "\n",
    "def train_virtual(init_model, ds, epochs=(1 if FAST else 3), lr=5e-4, bs=64):\n",
    "    m = copy.deepcopy(init_model).to(device)\n",
    "    opt = torch.optim.Adam(m.parameters(), lr=lr)\n",
    "    loader = DataLoader(ds, batch_size=bs, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    for _ in range(epochs):\n",
    "        m.train()\n",
    "        for x,y in loader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            loss = F.cross_entropy(m(x), y)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "    return m.eval()\n",
    "\n",
    "def avg_state_dicts(dicts):\n",
    "    avg = {}\n",
    "    for k in dicts[0].keys():\n",
    "        avg[k] = sum(d[k] for d in dicts) / len(dicts)\n",
    "    return avg\n",
    "\n",
    "# One virtual round (optional)\n",
    "virtual_states = []\n",
    "for ds in parts:\n",
    "    vm = train_virtual(student, ds, epochs=(1 if FAST else 2), lr=5e-4, bs=64)\n",
    "    virtual_states.append(vm.state_dict())\n",
    "student.load_state_dict(avg_state_dicts(virtual_states))\n",
    "\n",
    "print(\"After virtual retraining, student accuracy:\", eval_acc(student, eval_loader))\n"
   ],
   "id": "da45c0142dc901f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final student accuracy: 0.126\n",
      "After virtual retraining, student accuracy: 0.2424\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "23c8f6eb56974561"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
